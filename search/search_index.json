{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>This project focuses on developing a Face Recognition System for identifying Bollywood celebrities using deep learning techniques. The system can detect, recognize, and classify faces of popular Bollywood actors from images or videos. By leveraging Convolutional Neural Networks (CNNs) and Siamese Networks, the model learns unique facial features and accurately matches them against a pre-trained database of Bollywood stars.</p> <p>The project involves key steps such as Face Detection \u2192 Landmark Detection \u2192 Face Alignment \u2192 Face Embedding Generation \u2192 Face Recognition for accurate identification. Potential applications include celebrity identification in media, automated tagging in photos, and AI-powered fan engagement tools.</p>"},{"location":"#project-links","title":"Project Links:","text":"<ol> <li>Streamlit Webapp</li> <li>FastAPI Backend</li> <li>Github Repo</li> </ol>"},{"location":"#resources","title":"Resources","text":"No Description Dataset Preprocessing Modelling Weights 1 Face Detection Link Link Link Link 2 Face Keypoint Detection Link Link Link Link 3 Face Embedding - Siamese Link Link Link Link"},{"location":"face_alignment/","title":"Face Alignment","text":"<p>Face alignment is a preprocessing step in face recognition and analysis that ensures faces are properly oriented by detecting key landmarks and adjusting the facial position accordingly. By aligning faces before processing, models can achieve more robust and consistent results in tasks like face recognition and analysis.</p>"},{"location":"face_alignment/#keypoint-detection","title":"Keypoint Detection","text":"<p>Dlib's 68 Face Keypoint Detector provides precise landmark points, which are used to align faces. The key steps include:</p> <ul> <li>The model identifies 68 key points on the face, including the eyes, nose, mouth, and jawline.</li> <li>Using the eye positions, the tilt or rotation of the face is estimated.</li> <li>The image is rotated and scaled to align the eyes and mouth in a predefined standard position.</li> </ul>"},{"location":"face_alignment/#further-reading","title":"Further Reading","text":"<ul> <li>Face Alignment Explanation</li> <li>Face Keypoint Detection using Dlib</li> </ul>"},{"location":"face_detection/","title":"Face Detection","text":""},{"location":"face_detection/#faster-r-cnn","title":"Faster R-CNN","text":"<p>Faster R-CNN (Region-based Convolutional Neural Network) is a deep learning model designed for object detection, which identifies objects in an image and classifies them into categories. How It Works</p> <ul> <li>Feature Extraction - A convolutional neural network (CNN) extracts feature maps from the input image.</li> <li>Region Proposal Network (RPN) - Generates region proposals where objects might be located.</li> <li>ROI Pooling - Extracts fixed-size feature maps from proposed regions.</li> <li>Classification &amp; Bounding Box Regression - Classifies each region and refines bounding box coordinates.</li> </ul>"},{"location":"face_detection/#loss-function","title":"Loss Function","text":"<ol> <li> <p>Classification Loss (Cross-Entropy Loss): Ensures that the predicted class labels match the ground truth labels.</p> </li> <li> <p>Bounding Box Regression Loss (Smooth L1 Loss): Measures the accuracy of predicted bounding box coordinates compared to ground truth.</p> </li> </ol>"},{"location":"face_detection/#non-maximum-suppression-nms","title":"Non-Maximum Suppression (NMS)","text":"<p>Non-Maximum Suppression (NMS) is a post-processing technique used to eliminate redundant bounding boxes detected around the same object. NMS ensures that only the most relevant bounding box is retained for each detected object, improving detection accuracy and reducing false positives. It works as follows:</p> <ul> <li> <p>Sort detected bounding boxes by confidence scores.</p> </li> <li> <p>Select the highest confidence box and remove overlapping boxes with Intersection over Union (IoU) greater than a threshold.</p> </li> <li> <p>Repeat until no boxes remain.</p> </li> </ul>"},{"location":"face_detection/#further-reading","title":"Further Reading","text":"<ul> <li>Training Faster RCNN on Custom Dataset</li> <li>Mean Average Precision Metric</li> <li>Non Max Suppression</li> </ul>"},{"location":"face_recognition/","title":"Face Recognition","text":"<p>A face recognition system follows a structured pipeline: </p> <p>Face Detection \u2192 Landmark Detection \u2192 Face Alignment \u2192 Face Embedding Generation \u2192 Face Recognition</p>"},{"location":"face_recognition/#1-face-detection","title":"1. Face Detection","text":"<ul> <li>The first step in face recognition is detecting the face in an image or video.</li> <li>It involves identifying the location of faces and drawing bounding boxes around them.</li> <li>Faster RCNN Model is used for face detection.</li> </ul>"},{"location":"face_recognition/#2-face-keypoint-detection","title":"2. Face Keypoint Detection","text":"<ul> <li>Once a face is detected, key landmarks on the face (e.g., eyes, nose, mouth, jawline) are identified.</li> <li>These keypoints help in further processing such as alignment and feature extraction.</li> <li>Dlib\u2019s facial landmark detector, and MediaPipe are used for this task.</li> </ul>"},{"location":"face_recognition/#3-face-alignment","title":"3. Face Alignment","text":"<ul> <li>Faces in images may have variations due to different angles, lighting conditions, and expressions.</li> <li>Face alignment ensures all faces are oriented in a consistent manner before feature extraction.</li> <li>This step uses the detected keypoints for aligning eyes along a horizontal axis.</li> </ul>"},{"location":"face_recognition/#4-face-embedding-generation","title":"4. Face Embedding Generation","text":"<ul> <li>After aligning the face, a deep learning model extracts a feature vector (embedding) that uniquely represents the face.</li> <li>The Siamese network is used to convert a face into a high-dimensional feature vector.</li> </ul>"},{"location":"face_recognition/#5-face-recognition","title":"5. Face Recognition","text":"<ul> <li>The generated embeddings are compared with stored embeddings in a database using similarity metrics   like Euclidean Distance.</li> <li>Based on the similarity score, the system verifies whether two images belong to the same person.</li> </ul>"},{"location":"face_recognition/#further-reading","title":"Further Reading","text":"<ul> <li>Face Recognition Explaination</li> </ul>"},{"location":"siamese/","title":"Face Embedding","text":""},{"location":"siamese/#siamese-network","title":"Siamese Network","text":"<ul> <li>A Siamese Network is a type of neural network architecture that consists of two or more identical subnetworks, which share the same parameters, weights, and architecture. The purpose of this architecture is to learn a similarity function rather than a classification function.</li> <li>Siamese networks take in two input samples and pass them through the twin networks, producing embeddings (feature representations). These embeddings are then compared using a distance metric (such as Euclidean distance or cosine similarity) to determine whether the two inputs are similar or dissimilar.</li> <li>The model is trained with triplet loss, encouraging similar inputs to have closer embeddings and dissimilar inputs to have farther embeddings.</li> </ul>"},{"location":"siamese/#triplet-loss","title":"Triplet Loss","text":"<p>Triplet Loss is a loss function used to train models like Siamese Networks to learn similarity-based representations more effectively. The goal is to ensure that the anchor-positive distance is smaller than the anchor-negative distance by a margin. It operates on triplets of samples:</p> <ul> <li>Anchor (A): The reference sample.</li> <li>Positive (P): A sample similar to the anchor.</li> <li>Negative (N): A sample different from the anchor.</li> </ul>"},{"location":"siamese/#further-reading","title":"Further Reading","text":"<ul> <li>Siamese Network Explaination</li> <li>Creating Image Pairs for Siamese Network with Contrasive Loss</li> </ul>"}]}